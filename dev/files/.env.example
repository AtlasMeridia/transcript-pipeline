# Transcript Pipeline - Environment Configuration

# =============================================================================
# Transcription Settings
# =============================================================================

# Transcription engine: 'auto', 'captions', or 'mlx-whisper'
# - 'auto': Tries YouTube captions first, falls back to MLX Whisper (recommended)
# - 'captions': Only use YouTube auto-captions (fastest, but not always available)
# - 'mlx-whisper': Always use local MLX Whisper transcription
TRANSCRIPTION_ENGINE=auto

# Fallback engine when captions unavailable (used with 'auto' mode)
CAPTION_FALLBACK_ENGINE=mlx-whisper

# MLX Whisper model (Apple Silicon only)
# Options: tiny, base, small, medium, large, large-v3, large-v3-turbo, distil-large-v3
# Recommended: large-v3-turbo (fast + accurate)
MLX_WHISPER_MODEL=large-v3-turbo

# Caption language preference
CAPTION_LANGUAGE=en

# =============================================================================
# LLM Settings (for AI extraction/summarization)
# =============================================================================

# Default LLM for extraction: 'claude' or 'gpt'
DEFAULT_LLM=claude

# Anthropic API key (for Claude)
ANTHROPIC_API_KEY=your_anthropic_key_here

# OpenAI API key (for GPT) - optional if using Claude
# OPENAI_API_KEY=your_openai_key_here

# Model overrides (optional - uses sensible defaults)
# CLAUDE_MODEL_ID=claude-sonnet-4-5
# OPENAI_MODEL_ID=gpt-4o-mini

# =============================================================================
# Output Settings
# =============================================================================

# Base output directory
OUTPUT_DIR=./output

# =============================================================================
# Server Settings (for hosted deployment)
# =============================================================================

# CORS origins (comma-separated, or * for all)
CORS_ORIGINS=*

# Server port
PORT=8000
